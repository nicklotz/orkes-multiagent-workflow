{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a Multi-Agent Customer Support Triage System with Orkes Conductor\n",
    "\n",
    "This notebook demonstrates the technical implementation of a multi-agent system using Orkes Conductor to handle customer support ticket triage.\n",
    "\n",
    "## Architecture Overview\n",
    "\n",
    "Our system consists of three specialized AI agents:\n",
    "1. **Classifier Agent**: Analyzes ticket content to determine category, sentiment, and urgency\n",
    "2. **Knowledge Agent**: Searches internal documentation for relevant solutions\n",
    "3. **Escalation Agent**: Routes unresolved or high-priority tickets to human agents\n",
    "\n",
    "We'll also implement a custom worker task to demonstrate how external services can integrate with the workflow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Install Required Dependencies\n",
    "\n",
    "First, let's install the Orkes Conductor Python SDK and other dependencies we'll need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install conductor-python openai requests python-dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Import Libraries and Configure Conductor Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from conductor.client.configuration.configuration import Configuration\n",
    "from conductor.client.orkes_clients import OrkesClients\n",
    "from conductor.client.http.models import Task, WorkflowDef, TaskDef\n",
    "from conductor.client.worker.worker_task import WorkerTask\n",
    "from conductor.client.workflow.conductor_workflow import ConductorWorkflow\n",
    "from conductor.client.workflow.task.llm_tasks.llm_chat_complete import LlmChatComplete\n",
    "from conductor.client.workflow.task.simple_task import SimpleTask\n",
    "from conductor.client.workflow.task.switch_task import SwitchTask\n",
    "from conductor.client.workflow.executor.workflow_executor import WorkflowExecutor\n",
    "import json\n",
    "\n",
    "# Configure your Orkes Conductor instance\n",
    "# Get these from https://orkes.io/ after signing up for free\n",
    "configuration = Configuration(\n",
    "    server_api_url=\"https://play.orkes.io/api\",\n",
    "    key_id=\"YOUR_KEY_ID\",\n",
    "    key_secret=\"YOUR_KEY_SECRET\"\n",
    ")\n",
    "\n",
    "clients = OrkesClients(configuration)\n",
    "workflow_executor = WorkflowExecutor(configuration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Define the Classifier Agent\n",
    "\n",
    "The Classifier Agent uses an LLM to analyze incoming tickets and extract key information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_classifier_agent():\n",
    "    \"\"\"\n",
    "    Creates the classifier agent task that analyzes ticket content\n",
    "    Returns: category, sentiment, urgency\n",
    "    \"\"\"\n",
    "    classifier_prompt = \"\"\"\n",
    "    You are a customer support ticket classifier. Analyze the following support ticket and provide:\n",
    "    1. Category (billing, technical, account, general)\n",
    "    2. Sentiment (positive, neutral, negative, angry)\n",
    "    3. Urgency (low, medium, high, critical)\n",
    "    \n",
    "    Ticket: ${workflow.input.ticket_content}\n",
    "    \n",
    "    Respond in JSON format:\n",
    "    {\n",
    "      \"category\": \"<category>\",\n",
    "      \"sentiment\": \"<sentiment>\",\n",
    "      \"urgency\": \"<urgency>\",\n",
    "      \"reasoning\": \"<brief explanation>\"\n",
    "    }\n",
    "    \"\"\"\n",
    "    \n",
    "    classifier_task = LlmChatComplete(\n",
    "        task_ref_name=\"classify_ticket\",\n",
    "        llm_provider=\"openai\",\n",
    "        model=\"gpt-4\",\n",
    "        instructions=classifier_prompt,\n",
    "        messages=[{\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"${workflow.input.ticket_content}\"\n",
    "        }]\n",
    "    )\n",
    "    \n",
    "    return classifier_task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Define the Knowledge Agent\n",
    "\n",
    "The Knowledge Agent searches internal documentation and past resolutions to find potential solutions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_knowledge_agent():\n",
    "    \"\"\"\n",
    "    Creates the knowledge search agent that looks for solutions\n",
    "    in documentation, FAQs, and past tickets\n",
    "    \"\"\"\n",
    "    knowledge_prompt = \"\"\"\n",
    "    You are a knowledge base expert. Based on the ticket classification, \n",
    "    search for relevant solutions and provide recommendations.\n",
    "    \n",
    "    Ticket Content: ${workflow.input.ticket_content}\n",
    "    Category: ${classify_ticket.output.result.category}\n",
    "    Urgency: ${classify_ticket.output.result.urgency}\n",
    "    \n",
    "    Provide:\n",
    "    1. Relevant KB articles or documentation\n",
    "    2. Suggested resolution steps\n",
    "    3. Confidence level (0-100) that this resolves the issue\n",
    "    \n",
    "    Respond in JSON format:\n",
    "    {\n",
    "      \"kb_articles\": [\"article_id_1\", \"article_id_2\"],\n",
    "      \"resolution_steps\": [\"step1\", \"step2\"],\n",
    "      \"confidence\": <0-100>,\n",
    "      \"suggested_response\": \"<draft response to customer>\"\n",
    "    }\n",
    "    \"\"\"\n",
    "    \n",
    "    knowledge_task = LlmChatComplete(\n",
    "        task_ref_name=\"search_knowledge\",\n",
    "        llm_provider=\"openai\",\n",
    "        model=\"gpt-4\",\n",
    "        instructions=knowledge_prompt,\n",
    "        messages=[{\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Find solution for: ${workflow.input.ticket_content}\"\n",
    "        }]\n",
    "    )\n",
    "    \n",
    "    return knowledge_task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Create Custom Worker Task for Notification\n",
    "\n",
    "This worker task demonstrates how to implement custom business logic that runs outside of Conductor but is orchestrated by it. This worker will handle sending notifications to Slack or email when tickets are escalated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from conductor.client.worker.worker_task import WorkerTask\n",
    "\n",
    "@WorkerTask(task_definition_name='send_escalation_notification', domain='support', poll_interval=0.5)\n",
    "def send_notification(task_input):\n",
    "    \"\"\"\n",
    "    Custom worker that sends notifications when tickets are escalated.\n",
    "    This worker polls Conductor for tasks and executes them.\n",
    "    \n",
    "    Args:\n",
    "        task_input: Dictionary containing ticket details and escalation info\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with notification status\n",
    "    \"\"\"\n",
    "    ticket_id = task_input.get('ticket_id')\n",
    "    urgency = task_input.get('urgency')\n",
    "    category = task_input.get('category')\n",
    "    assigned_to = task_input.get('assigned_to', 'support-team')\n",
    "    \n",
    "    print(f\"ðŸš¨ Escalating ticket {ticket_id}\")\n",
    "    print(f\"   Category: {category}\")\n",
    "    print(f\"   Urgency: {urgency}\")\n",
    "    print(f\"   Assigned to: {assigned_to}\")\n",
    "    \n",
    "    # In production, you would send actual notifications here:\n",
    "    # - Slack webhook\n",
    "    # - Email via SendGrid/SES\n",
    "    # - PagerDuty for critical issues\n",
    "    # - Update ticketing system (Zendesk, Jira, etc.)\n",
    "    \n",
    "    notification_channels = []\n",
    "    \n",
    "    if urgency in ['critical', 'high']:\n",
    "        notification_channels.extend(['slack', 'email', 'pagerduty'])\n",
    "    else:\n",
    "        notification_channels.append('email')\n",
    "    \n",
    "    # Simulate sending notifications\n",
    "    results = {\n",
    "        'notification_sent': True,\n",
    "        'channels': notification_channels,\n",
    "        'timestamp': '2025-01-15T10:30:00Z',\n",
    "        'assigned_team': assigned_to\n",
    "    }\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Define the Escalation Logic\n",
    "\n",
    "Based on the knowledge agent's confidence and the ticket urgency, we'll decide whether to auto-resolve or escalate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_escalation_decision():\n",
    "    \"\"\"\n",
    "    Creates a switch task that routes tickets based on confidence and urgency\n",
    "    \"\"\"\n",
    "    # This is a simple task that evaluates escalation criteria\n",
    "    escalation_eval = SimpleTask(\n",
    "        task_def_name=\"evaluate_escalation\",\n",
    "        task_reference_name=\"eval_escalation\"\n",
    "    )\n",
    "    \n",
    "    # Worker task for sending notifications\n",
    "    notification_task = SimpleTask(\n",
    "        task_def_name=\"send_escalation_notification\",\n",
    "        task_reference_name=\"notify_team\",\n",
    "        inputs={\n",
    "            'ticket_id': '${workflow.input.ticket_id}',\n",
    "            'urgency': '${classify_ticket.output.result.urgency}',\n",
    "            'category': '${classify_ticket.output.result.category}',\n",
    "            'assigned_to': '${eval_escalation.output.assigned_team}'\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    return escalation_eval, notification_task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Build the Complete Workflow\n",
    "\n",
    "Now we'll assemble all agents into a cohesive workflow that orchestrates the entire triage process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_support_triage_workflow():\n",
    "    \"\"\"\n",
    "    Creates the complete multi-agent support triage workflow\n",
    "    \"\"\"\n",
    "    workflow = ConductorWorkflow(\n",
    "        name=\"customer_support_triage\",\n",
    "        version=1,\n",
    "        executor=workflow_executor\n",
    "    )\n",
    "    \n",
    "    # Add all tasks in sequence\n",
    "    classifier = create_classifier_agent()\n",
    "    knowledge = create_knowledge_agent()\n",
    "    escalation_eval, notification = create_escalation_decision()\n",
    "    \n",
    "    # Build the workflow chain\n",
    "    workflow >> classifier >> knowledge >> escalation_eval\n",
    "    \n",
    "    # Add conditional notification based on escalation\n",
    "    workflow >> notification\n",
    "    \n",
    "    return workflow\n",
    "\n",
    "# Create and register the workflow\n",
    "support_workflow = create_support_triage_workflow()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Register the Worker\n",
    "\n",
    "The worker needs to be running to poll for tasks. In production, this would be a separate service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from conductor.client.automator.task_handler import TaskHandler\n",
    "\n",
    "# Create task handler and register the worker\n",
    "task_handler = TaskHandler(\n",
    "    workers=[send_notification],\n",
    "    configuration=configuration,\n",
    "    scan_for_annotated_workers=False\n",
    ")\n",
    "\n",
    "# Start polling for tasks (in production, this runs as a daemon)\n",
    "# task_handler.start_processes()\n",
    "\n",
    "print(\"âœ… Worker registered and ready to process tasks\")\n",
    "print(\"   Task Definition: send_escalation_notification\")\n",
    "print(\"   Domain: support\")\n",
    "print(\"   Poll Interval: 0.5s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9: Test the Workflow\n",
    "\n",
    "Let's test our multi-agent system with sample support tickets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample test tickets\n",
    "test_tickets = [\n",
    "    {\n",
    "        \"ticket_id\": \"TKT-001\",\n",
    "        \"ticket_content\": \"I can't log into my account. I've tried resetting my password but I'm not receiving the email.\"\n",
    "    },\n",
    "    {\n",
    "        \"ticket_id\": \"TKT-002\",\n",
    "        \"ticket_content\": \"URGENT: Our production system is down and we're losing money every minute. This is critical!\"\n",
    "    },\n",
    "    {\n",
    "        \"ticket_id\": \"TKT-003\",\n",
    "        \"ticket_content\": \"Hi, I was charged twice for my subscription this month. Can you help?\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# Execute workflows for each ticket\n",
    "for ticket in test_tickets:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Processing: {ticket['ticket_id']}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Execute the workflow\n",
    "    workflow_id = support_workflow.execute(\n",
    "        workflow_input=ticket\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nâœ… Workflow started with ID: {workflow_id}\")\n",
    "    print(f\"   View in Conductor UI: https://play.orkes.io/execution/{workflow_id}\")\n",
    "    \n",
    "    # In production, you would monitor workflow status:\n",
    "    # workflow_status = workflow_executor.get_workflow(workflow_id)\n",
    "    # print(f\"   Status: {workflow_status.status}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 10: Monitor and Debug\n",
    "\n",
    "Orkes Conductor provides powerful monitoring capabilities. Here's how to check workflow execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def monitor_workflow(workflow_id):\n",
    "    \"\"\"\n",
    "    Retrieve and display workflow execution details\n",
    "    \"\"\"\n",
    "    workflow_client = clients.get_workflow_client()\n",
    "    execution = workflow_client.get_workflow(workflow_id, include_tasks=True)\n",
    "    \n",
    "    print(f\"\\nWorkflow Status: {execution.status}\")\n",
    "    print(f\"\\nTask Execution Details:\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    for task in execution.tasks:\n",
    "        print(f\"\\nðŸ“‹ {task.task_type}: {task.reference_task_name}\")\n",
    "        print(f\"   Status: {task.status}\")\n",
    "        print(f\"   Start Time: {task.start_time}\")\n",
    "        print(f\"   End Time: {task.end_time}\")\n",
    "        \n",
    "        if task.output_data:\n",
    "            print(f\"   Output: {json.dumps(task.output_data, indent=2)[:200]}...\")\n",
    "    \n",
    "    return execution\n",
    "\n",
    "# Example usage:\n",
    "# execution_details = monitor_workflow(workflow_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This implementation demonstrates:\n",
    "\n",
    "1. **Multi-Agent Orchestration**: Three specialized AI agents (Classifier, Knowledge, Escalation) working together\n",
    "2. **Custom Worker Integration**: A worker task that polls Conductor and executes external business logic\n",
    "3. **Workflow Composition**: Using Conductor's SDK to build complex workflows with conditional logic\n",
    "4. **Monitoring & Observability**: Built-in capabilities to track workflow execution\n",
    "\n",
    "### Key Takeaways:\n",
    "\n",
    "- **Separation of Concerns**: Each agent has a single, well-defined responsibility\n",
    "- **Scalability**: Workers can be scaled independently based on load\n",
    "- **Reliability**: Conductor handles retries, error handling, and task persistence\n",
    "- **Flexibility**: Easy to add new agents or modify the workflow without changing agent code\n",
    "\n",
    "### Next Steps:\n",
    "\n",
    "1. Integrate with your actual LLM provider and knowledge base\n",
    "2. Add error handling and retry policies\n",
    "3. Implement real notification channels (Slack, Email, PagerDuty)\n",
    "4. Set up monitoring and alerting\n",
    "5. Deploy workers as containerized services\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
